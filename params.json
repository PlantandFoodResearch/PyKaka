{
  "name": "Pykaka",
  "tagline": "Kaka, Science Data, Cache, Genotype Data",
  "body": "# Python API for Kaka\r\n\r\n## Tools used\r\n\r\n- Python 2/3\r\n- Mongo connectors\r\n- KAKAs restful API\r\n- Jupyter notebooks in form of a Pyrat\r\n\r\n## Background \r\n\r\nPyKaka is a Python API for downloading data from [Kaka](https://github.com/hdzierz/Kaka). The Python API works from any python 2.7 and 3.5+ python installation. Kaka can be run using docker and comes with a Pyrat pre-installed. If you e.g. load Kaka on server just-a-test.powerplant.pfr.co.nz then your Pyrat jupyter notebookd will run on just-a-test.powerplant.pfr.co.nz:8889. \r\n\r\n## Installation\r\n\r\nWhen using A Kaka docker setup you will have a pyrat running on port 8889. You will find that the Kaka Python API has been pre-installed. Thus, the following import should just work:\r\n\r\n```\r\nfrom PyKaka.api import *\r\n```\r\n\r\nIf it does not you need to install it via:\r\n\r\n```\r\npip install git+https://github.com/hdzierz/PyKaka.git\r\n```\r\n\r\n## Queries\r\n \r\nThe syntax for the API is as follows:\r\n\r\n```\r\nKaka.qry(realm='some_realm', qry='some_query', mode='a-mode') \r\n```\r\n\r\nWhereby:\r\n\r\n\"realm\" can currrently be:\r\n\r\n- genotype\r\n- design\r\n- experiment\r\n- term\r\n\r\n\"qry\":\r\n\r\nThis is a pql query. For more info see: [pql](https://github.com/alonho/pql)\r\n\r\n\"mode\":\r\n\r\n- pql (default)\r\n- mongo (can perform better for larger queries)\r\n\r\nReturn value:\r\n\r\nThe return value is a [pandas](http://pandas.pydata.org/) data frame.\r\n\r\nQuery for an ID:\r\n\r\nIDs are unfirntunately a but special as we have a MongoDB in the background. I do promise to simplify this. However, teh query for an ID goes as follows:\r\n\r\n```\r\ndat = Kaka.qry('genotype', \"_id=id(a_key)\")\r\nprint(dat)\r\n\r\n```\r\n\r\nOr linking to a reference:\r\n\r\n```\r\ndat = Kaka.qry('genotype', \"experiment_obj=id(a_key)\")\r\nprint(dat)\r\n\r\n```\r\n\r\nImportant is that you wrap the 'id' function around the Mongo ID. \r\n\r\n\r\n**Example:**\r\n\r\nThe databse is loaded with a gene expression data set. To obtain these data from Kaka you run:\r\n\r\n```\r\ndat = Kaka.qry('genotype', \"experiment=='Gene Expression' and gene=='AT1G02930.2'\")\r\nprint(dat)\r\n```\r\n\r\n\r\n<div>\r\n<table border=\"1\" class=\"dataframe\">\r\n  <thead>\r\n    <tr style=\"text-align: right;\">\r\n      <th></th>\r\n      <th>PFD1001L3R1</th>\r\n      <th>PFD1001L3R2</th>\r\n      <th>PFD1001L4R1</th>\r\n      <th>PFD1001L4R2</th>\r\n      <th>PFD1002L3R1</th>\r\n      <th>PFD1002L3R2</th>\r\n      <th>PFD1002L4R1</th>\r\n      <th>PFD1002L4R2</th>\r\n      <th>PFD2501L3R1</th>\r\n      <th>PFD2501L3R2</th>\r\n      <th>...</th>\r\n      <th>experiment</th>\r\n      <th>gene</th>\r\n      <th>gene_name</th>\r\n      <th>group</th>\r\n      <th>lastupdateddate</th>\r\n      <th>length</th>\r\n      <th>name</th>\r\n      <th>obs</th>\r\n      <th>statuscode</th>\r\n      <th>study</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>0</th>\r\n      <td>301</td>\r\n      <td>301</td>\r\n      <td>259</td>\r\n      <td>270</td>\r\n      <td>281</td>\r\n      <td>286</td>\r\n      <td>274</td>\r\n      <td>266</td>\r\n      <td>750</td>\r\n      <td>711</td>\r\n      <td>...</td>\r\n      <td>gene_expression</td>\r\n      <td>AT1G02930.2</td>\r\n      <td>glutathione S-transferase 6</td>\r\n      <td>unknown</td>\r\n      <td>2016-03-04 09:45:42.372</td>\r\n      <td>866</td>\r\n      <td>AT1G02930.2</td>\r\n      <td>{}</td>\r\n      <td>1</td>\r\n      <td>56d8a2ca32d3300001f6f338</td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n<p>1 rows Ã— 48 columns</p>\r\n</div>\r\n\r\nGene expression data (any data really) can be supplemented with exprimental design information similar to teh old micro array targets file [targets](http://svitsrv25.epfl.ch/R-doc/library/limma/html/readTargets.html):\r\n\r\n```\r\ndat = Kaka.qry('design', \"experiment=='Gene Expression'\")\r\nprint(dat)\r\n```\r\n\r\n```\r\n     phenotype  condition         typ\r\n0  PFD1001L3R1    treated  paired-end\r\n1  PFD1001L3R2    treated  paired-end\r\n2  PFD1001L4R1    treated  paired-end\r\n3  PFD1001L4R2    treated  paired-end\r\n4  PFD1002L3R1  untreated  paired-end\r\n5  PFD1002L3R2  untreated  paired-end\r\n6  PFD1002L4R1  untreated  paired-end\r\n7  PFD1002L4R2  untreated  paired-end\r\n```\r\n\r\n\r\n\r\n## Getting Data In\r\n\r\nPyKaka has the ability to process data into the database. All data will be associated with an Experiment as well as a DataSource. Each Experiment and DataSource has a unique name. These names are impartant as\r\n all operations (delete data, reload data, load data) will be associated with them. There cannot be two Experiments or DataSources with the same name. The Experiment also requires\r\nsome basic meta info (please see config file below).\r\n\r\nThe method you can use for sending data is called \"send\" and is part of the Kaka api:\r\n\r\n```\r\nKaka.send(data,config)\r\n```\r\n\r\nWhereby:\r\n\r\n- data is your data set which can be either a pandas DataFrame or an array of dicts. **The data needs a unique ID column!** \r\n- config is a configuration dict\r\n\r\n**The configuration dict:**\r\n\r\nThe configuration dict needs the following entries:\r\n\r\n- Experiment \r\n - Code: A unique name of the experiment the data are associated with. Please use characters, numbers and underscores only.\r\n - Date: The Date of your experiment\r\n - Description: A brief description of your experiment\r\n - Password: Allocate a password. This will protect your experiment from others overriding your data.\r\n - PI: Who is the PI of the experiment\r\n - Realm: The realm your experiment belongs to (e.g. Genotype or Seafood). You cannot create a new one. Please contact admin as above\r\n- DataSource\r\n - Format: Can only be **python_dict** at the moment\r\n - ID Column: Your data requires a unique ID column\r\n - Name: This can be either a path to a file or a unique name of your data set\r\n - Group: Data might be grouped in an experiment like treatments [optional]\r\n - Creator: Who has craeted the data?\r\n - Contact: A contact email address \r\n - Mode: Can be \"Clean\", \"Override\", \"Append\"\r\n\r\nJust a wee explanation about the **Mode**:\r\n\r\n**Override:** This will delete all data in the experiment for your DataSource before your data is loaded. \r\n**Clean:** This will delete all data in a DataSource associated with your experiment\r\n**Append:** Append will not delete anything but append all data you specify to the DataSource in an Experiment \r\n**Destroy:** All above modes leave  trace of the experiment and DataSources. Destroy will also clean those.\r\n\r\n\r\n** Example of a config dict for loading a hapmap into Kaka:**\r\n\r\n```\r\nconfig = {\r\n    \"DataSource\":{\r\n        \"Format\": \"python_dict\",\r\n        \"ID Column\": \"rs#\" , \r\n        \"Name\": '/tmp/',\r\n        \"Group\": \"None\",\r\n        \"Creator\": \"Helge\",\r\n        \"Contact\": \"helge.dzierzon@plantandfood.co.nz\",\r\n    },\r\n    \"Experiment\":{\r\n        \"Code\": \"HapMap_Test\",\r\n        \"Date\": \"2016-01-07\",\r\n        \"Description\": \"REST test\",\r\n        \"Realm\": \"Genotype\",\r\n        \"Mode\": \"Override\",\r\n        \"Password\": \"inkl67z\",\r\n        \"PI\": \"Willi Wimmer\",\r\n        \"Species\": \"Cymbidium\",\r\n    }\r\n}\r\n```\r\n\r\n## Configuring teh host and port\r\n\r\nIf you don't acccess the pyrat docker instance you  need to configure the host and port. PyKaka uses a cfg structure:\r\n\r\n```\r\ncfg[\"web_host\"] = 'biopvm201.pfr.co.nz'\r\ncfg[\"web_port\"] = \"8001\"\r\nKaka.qry(..., cfg=cfg)\r\n```\r\n\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}